{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66ab3cc5-aee4-415a-9391-1e5d37ccaf1d",
   "metadata": {},
   "source": [
    "# Internet Search using Bing API - Bing Chat Clone"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "306fc0a9-4044-441d-9ba7-f54f32e6ea9f",
   "metadata": {},
   "source": [
    "In this notebook, we'll delve into the ways in which you can **boost your GPT Smart Search Engine with web search functionalities**, utilizing both Langchain and the Azure Bing Search API service.\n",
    "\n",
    "As previously discussed in our other notebooks, **harnessing agents and tools is an effective approach**. We aim to leverage the capabilities of OpenAI's large language models (LLM), such as GPT-4 and its successors, to perform the heavy lifting of reasoning and researching on our behalf.\n",
    "\n",
    "There are numerous instances where it is necessary for our Smart Search Engine to have internet access. For instance, we may wish to **enrich an answer with information available on the web**, or **provide users with up-to-date and recent information**. Regardless of the scenario, we require our engine to base its responses on search results.\n",
    "\n",
    "By the conclusion of this notebook, you'll have a solid understanding of the **Bing Search API basics**, including **how to create a Web Search Agent using the Bing Search API**, and how these tools can **strengthen your chatbot**. Additionally, you'll learn about **Callback Handlers, their use, and their significance in bot applications**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1fb79a3-4856-4721-988c-112813690a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from typing import Dict, List\n",
    "from pydantic import BaseModel, Extra, root_validator\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.utilities import BingSearchAPIWrapper\n",
    "\n",
    "from common.callbacks import MyCustomHandler\n",
    "from common.prompts import BING_PROMPT_PREFIX\n",
    "\n",
    "from IPython.display import Markdown, HTML, display  \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials2.env\")\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "    \n",
    "MODEL_DEPLOYMENT_NAME = \"gpt4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87a3f22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://openai-demo-poc-3232.openai.azure.com/\"\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "258a6e99-2d4f-4147-b8ee-c64c85296181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2354238d",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIConnectionError",
     "evalue": "Error communicating with OpenAI: Invalid URL 'ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview': No scheme supplied. Perhaps you meant https://ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\source\\.conda\\lib\\site-packages\\openai\\api_requestor.py:596\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[1;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    597\u001b[0m         method,\n\u001b[0;32m    598\u001b[0m         abs_url,\n\u001b[0;32m    599\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    600\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m    601\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    602\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    603\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[0;32m    604\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[0;32m    605\u001b[0m     )\n\u001b[0;32m    606\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\source\\.conda\\lib\\site-packages\\requests\\sessions.py:575\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    563\u001b[0m req \u001b[39m=\u001b[39m Request(\n\u001b[0;32m    564\u001b[0m     method\u001b[39m=\u001b[39mmethod\u001b[39m.\u001b[39mupper(),\n\u001b[0;32m    565\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    573\u001b[0m     hooks\u001b[39m=\u001b[39mhooks,\n\u001b[0;32m    574\u001b[0m )\n\u001b[1;32m--> 575\u001b[0m prep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_request(req)\n\u001b[0;32m    577\u001b[0m proxies \u001b[39m=\u001b[39m proxies \u001b[39mor\u001b[39;00m {}\n",
      "File \u001b[1;32mc:\\source\\.conda\\lib\\site-packages\\requests\\sessions.py:486\u001b[0m, in \u001b[0;36mSession.prepare_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    485\u001b[0m p \u001b[39m=\u001b[39m PreparedRequest()\n\u001b[1;32m--> 486\u001b[0m p\u001b[39m.\u001b[39;49mprepare(\n\u001b[0;32m    487\u001b[0m     method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod\u001b[39m.\u001b[39;49mupper(),\n\u001b[0;32m    488\u001b[0m     url\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m     files\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mfiles,\n\u001b[0;32m    490\u001b[0m     data\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mdata,\n\u001b[0;32m    491\u001b[0m     json\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mjson,\n\u001b[0;32m    492\u001b[0m     headers\u001b[39m=\u001b[39;49mmerge_setting(\n\u001b[0;32m    493\u001b[0m         request\u001b[39m.\u001b[39;49mheaders, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheaders, dict_class\u001b[39m=\u001b[39;49mCaseInsensitiveDict\n\u001b[0;32m    494\u001b[0m     ),\n\u001b[0;32m    495\u001b[0m     params\u001b[39m=\u001b[39;49mmerge_setting(request\u001b[39m.\u001b[39;49mparams, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams),\n\u001b[0;32m    496\u001b[0m     auth\u001b[39m=\u001b[39;49mmerge_setting(auth, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauth),\n\u001b[0;32m    497\u001b[0m     cookies\u001b[39m=\u001b[39;49mmerged_cookies,\n\u001b[0;32m    498\u001b[0m     hooks\u001b[39m=\u001b[39;49mmerge_hooks(request\u001b[39m.\u001b[39;49mhooks, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhooks),\n\u001b[0;32m    499\u001b[0m )\n\u001b[0;32m    500\u001b[0m \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[1;32mc:\\source\\.conda\\lib\\site-packages\\requests\\models.py:368\u001b[0m, in \u001b[0;36mPreparedRequest.prepare\u001b[1;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_method(method)\n\u001b[1;32m--> 368\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_url(url, params)\n\u001b[0;32m    369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_headers(headers)\n",
      "File \u001b[1;32mc:\\source\\.conda\\lib\\site-packages\\requests\\models.py:439\u001b[0m, in \u001b[0;36mPreparedRequest.prepare_url\u001b[1;34m(self, url, params)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m scheme:\n\u001b[1;32m--> 439\u001b[0m     \u001b[39mraise\u001b[39;00m MissingSchema(\n\u001b[0;32m    440\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid URL \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m!r}\u001b[39;00m\u001b[39m: No scheme supplied. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    441\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPerhaps you meant https://\u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    442\u001b[0m     )\n\u001b[0;32m    444\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m host:\n",
      "\u001b[1;31mMissingSchema\u001b[0m: Invalid URL 'ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview': No scheme supplied. Perhaps you meant https://ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview?",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m      2\u001b[0m               engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt4\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      3\u001b[0m               messages\u001b[39m=\u001b[39;49m[\n\u001b[0;32m      4\u001b[0m                     {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mYou are a helpful assistant.\u001b[39;49m\u001b[39m\"\u001b[39;49m},\n\u001b[0;32m      5\u001b[0m                     {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mWho won the world series in 2020?\u001b[39;49m\u001b[39m\"\u001b[39;49m}\n\u001b[0;32m      6\u001b[0m                 ]\n\u001b[0;32m      7\u001b[0m             )\n\u001b[0;32m      9\u001b[0m \u001b[39m# print the response\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mprint\u001b[39m(response[\u001b[39m'\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\source\\.conda\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\source\\.conda\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\source\\.conda\\lib\\site-packages\\openai\\api_requestor.py:288\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m--> 288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[0;32m    291\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    292\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    293\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    294\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    295\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[0;32m    298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\source\\.conda\\lib\\site-packages\\openai\\api_requestor.py:609\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[1;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    607\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    608\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 609\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mAPIConnectionError(\n\u001b[0;32m    610\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mError communicating with OpenAI: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)\n\u001b[0;32m    611\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    612\u001b[0m util\u001b[39m.\u001b[39mlog_debug(\n\u001b[0;32m    613\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mOpenAI API response\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    614\u001b[0m     path\u001b[39m=\u001b[39mabs_url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    617\u001b[0m     request_id\u001b[39m=\u001b[39mresult\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mX-Request-Id\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    618\u001b[0m )\n\u001b[0;32m    619\u001b[0m \u001b[39m# Don't read the whole stream for debug logging unless necessary.\u001b[39;00m\n",
      "\u001b[1;31mAPIConnectionError\u001b[0m: Error communicating with OpenAI: Invalid URL 'ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview': No scheme supplied. Perhaps you meant https://ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview?"
     ]
    }
   ],
   "source": [
    "    response = openai.ChatCompletion.create(\n",
    "                  engine=\"gpt4\",\n",
    "                  messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"}\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "    # print the response\n",
    "    print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e8e0b32-a6b5-4b1c-943d-e57b737213fa",
   "metadata": {},
   "source": [
    "## Introduction to Callback Handlers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "003327ac-2851-48ef-8a6b-2d8c2004bb2e",
   "metadata": {},
   "source": [
    "This following explanation comes directly from the Langchain documentation about Callbacks ([HERE](https://python.langchain.com/docs/modules/callbacks/)):\n",
    "\n",
    "**Callbacks**:<br>\n",
    "LangChain provides a callbacks system that allows you to hook into the various stages of your LLM application. This is useful for logging, monitoring, streaming, and other tasks.\n",
    "\n",
    "You can subscribe to these events by using the callbacks argument available throughout the API. This argument is list of handler objects, which are expected to implement one or more of the methods described below in more detail.\n",
    "\n",
    "**Callback handlers**:<br>\n",
    "CallbackHandlers are objects that implement the CallbackHandler interface, which has a method for each event that can be subscribed to. The CallbackManager will call the appropriate method on each handler when the event is triggered.\n",
    "\n",
    "--------------------\n",
    "We will incorporate a handler for the callbacks, enabling us to observe the response as it streams and to gain insights into the Agent's reasoning process. This will prove incredibly valuable when we aim to stream the bot's responses to users and keep them informed about the ongoing process as they await the answer.\n",
    "\n",
    "Our custom handler is on the folder `common/callbacks.py`. Go a take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d3daf03-77e2-466e-a255-2f06bee3561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_handler = MyCustomHandler()\n",
    "cb_manager = CallbackManager(handlers=[cb_handler])\n",
    "\n",
    "# Now we declare our LLM object with the callback handler \n",
    "llm = AzureChatOpenAI(deployment_name=MODEL_DEPLOYMENT_NAME, temperature=0.5, max_tokens=500,\n",
    "                      streaming=True, callback_manager=cb_manager)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11da70c2-60b6-47fb-94f1-aa11291fa40c",
   "metadata": {},
   "source": [
    "## Creating a custom tool - Bing Search API tool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4dc30c9d-605d-4ada-9358-f926aeed2e48",
   "metadata": {},
   "source": [
    "Langhain has already a pre-created tool called BingSearchAPIWrapper ([HERE](https://github.com/hwchase17/langchain/blob/master/langchain/utilities/bing_search.py)), however we are going to make it a bit better by using the results function instead of the run function, that way we not only have the text results, but also the title and link(source) of each snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3d155ae-16eb-458a-b2ed-5aa9a9b84ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBingSearch(BaseTool):\n",
    "    \"\"\"Tool for a Bing Search Wrapper\"\"\"\n",
    "    \n",
    "    name = \"@bing\"\n",
    "    description = \"useful when the questions includes the term: @bing.\\n\"\n",
    "\n",
    "    k: int = 5\n",
    "    \n",
    "    def _run(self, query: str) -> str:\n",
    "        bing = BingSearchAPIWrapper(k=self.k)\n",
    "        return bing.results(query,num_results=self.k)\n",
    "            \n",
    "    async def _arun(self, query: str) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"ChatGPTTool does not support async\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a3d6569-0c61-4b1c-9263-431304577551",
   "metadata": {},
   "source": [
    "Now, we create our REACT agent that uses our custom tool and our custom prompt `BING_PROMPT_PREFIX`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c6cf721-76bb-47b6-aeeb-9ff4ff92b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [MyBingSearch(k=5)]\n",
    "agent_executor = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "                         agent_kwargs={'prefix':BING_PROMPT_PREFIX})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7232260e-e972-4288-b0b5-0b605e584528",
   "metadata": {},
   "source": [
    "Try some of the below questions, or others that you might like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa949cea-c9aa-4529-a75f-61084ffffd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"How much is 50 USD in Euros and is it enough for a 5 star hotel in Frankfurt?\"\n",
    "# QUESTION = \"My son needs to build a pinewood car for a pinewood derbi, how do I build such a car?\"\n",
    "# QUESTION = \"Who won the last superbowl?\"\n",
    "# QUESTION = \"What is the deal with Joe Biden's son?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca910f71-60fb-4758-b4a9-757e37eb421f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: Invalid URL 'ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview': No scheme supplied. Perhaps you meant https://ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview?.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: Invalid URL 'ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview': No scheme supplied. Perhaps you meant https://ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview?.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: Invalid URL 'ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview': No scheme supplied. Perhaps you meant https://ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview?.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: Invalid URL 'ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview': No scheme supplied. Perhaps you meant https://ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview?.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 16.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: Invalid URL 'ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview': No scheme supplied. Perhaps you meant https://ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview?.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: Invalid URL 'ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview': No scheme supplied. Perhaps you meant https://ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview?.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Error: Error communicating with OpenAI: Invalid URL 'ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview': No scheme supplied. Perhaps you meant https://ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: Invalid URL 'ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview': No scheme supplied. Perhaps you meant https://ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview?.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: Invalid URL 'ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview': No scheme supplied. Perhaps you meant https://ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview?.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: Invalid URL 'ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview': No scheme supplied. Perhaps you meant https://ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview?.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 16.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: Invalid URL 'ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview': No scheme supplied. Perhaps you meant https://ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview?.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Error: Error communicating with OpenAI: Invalid URL 'ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview': No scheme supplied. Perhaps you meant https://ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview?\n"
     ]
    }
   ],
   "source": [
    "#As LLMs responses are never the same, we do a for loop in case the answer cannot be parsed according to our prompt instructions\n",
    "for i in range(2):\n",
    "    try:\n",
    "        response = agent_executor.run(QUESTION) \n",
    "        break\n",
    "    except Exception as e:\n",
    "        response = str(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cd62692-8421-41f0-a780-0e1106fd830e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Error communicating with OpenAI: Invalid URL 'ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview': No scheme supplied. Perhaps you meant https://ENTER YOUR VALUE/openai/deployments/gpt4/chat/completions?api-version=2023-03-15-preview?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9782fafa-9453-46be-b9d7-b33088f61ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you want to take a look at the custom bing search prompt\n",
    "# printmd(agent_executor.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56cbc405-26e2-471e-9626-2a0df07f5ddc",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7381ea5f-7269-4e1f-8b0c-1e2c04bd84c0",
   "metadata": {},
   "source": [
    "In this notebook, we learned about Callback Handlers and how to stream the response from the LLM. We also learn how to create a Bing Chat clone using a clever prompt with specific search and formatting instructions.\n",
    "\n",
    "The result is an agent that can smartly search the web for us and give us the answer to our question with the right url citations and links!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02073623-91b4-40d6-8eaf-cb6d9c6a7a9a",
   "metadata": {},
   "source": [
    "# NEXT\n",
    "\n",
    "The Next Notebook will guide you on how we stick everything together. How do we use the features of all notebooks and create a brain agent that can respond to any request accordingly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
